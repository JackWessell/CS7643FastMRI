{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\pinkp\\Anaconda3\\envs\\AdvML\\lib\\site-packages\\scipy\\__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.4\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "'''%load_ext autoreload\n",
    "%autoreload 2\n",
    "'''\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as tvtransforms\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import fastmri\n",
    "from fastmri.data import subsample\n",
    "from fastmri.data import transforms, mri_data\n",
    "from fastmri.losses import SSIMLoss\n",
    "\n",
    "from models.mymodels import FastMRICVT, FastMRIEncoderDecoder\n",
    "import json\n",
    "import pytorch_lightning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "spec ={\n",
    "    'INIT': 'trunc_norm',\n",
    "    'NUM_STAGES': 3,\n",
    "    'PATCH_SIZE': [5, 3, 3],\n",
    "    'PATCH_STRIDE': [2, 2, 2],\n",
    "    'PATCH_PADDING': [1, 1,1],\n",
    "    'DIM_EMBED': [32, 128, 196],\n",
    "    'NUM_HEADS': [1, 4, 8],\n",
    "    'DEPTH': [1, 2, 8],\n",
    "    'MLP_RATIO': [4.0, 4.0,4.0],\n",
    "    'ATTN_DROP_RATE': [0.0, 0.0,0.0],\n",
    "    'DROP_RATE': [0.0, 0.0,0,0],\n",
    "    'DROP_PATH_RATE': [0.0, 0.0,0.0],\n",
    "    'QKV_BIAS': [True, True,True],\n",
    "    'CLS_TOKEN': [False, False, False],\n",
    "    'POS_EMBED': [False, False, False],\n",
    "    'QKV_PROJ_METHOD': ['dw_bn', 'dw_bn', 'dw_bn'],\n",
    "    'KERNEL_QKV': [3, 3, 3],\n",
    "    'PADDING_KV': [1, 1,1],\n",
    "    'STRIDE_KV': [2, 2,2],\n",
    "    'PADDING_Q': [1, 1,1],\n",
    "    'STRIDE_Q': [1, 1,1]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    " mask_func = subsample.RandomMaskFunc(\n",
    "        center_fractions=[0.08, 0.04],\n",
    "        accelerations=[4, 8]    \n",
    "        )   \n",
    "train = mri_data.SliceDataset(\n",
    "    root='../singlecoil_val',\n",
    "    transform=transforms.UnetDataTransform('singlecoil', mask_func=mask_func),\n",
    "    challenge='singlecoil'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 100\n",
    "learning_rate = 1e-4\n",
    "weight_decay = 1e-16\n",
    "batch_size = 4\n",
    "\n",
    "#device = torch.device('cuda')\n",
    "device = torch.device('cpu')\n",
    "\n",
    "model = FastMRICVT(spec=spec).to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr =learning_rate, weight_decay=weight_decay)\n",
    "scheduler= torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, epochs)\n",
    "log_every = 10\n",
    "criterion = SSIMLoss()\n",
    "criterion.w = criterion.w.to(device)\n",
    "l2 = torch.nn.MSELoss()\n",
    "\n",
    "def train_loop(epoch, model, loader):\n",
    "    model.train()\n",
    "    i = 0\n",
    "    results = {'loss': 0, 'counter': 0, 'loss_arr':[]}\n",
    "    \n",
    "    for inputs, targets, max_val in loader:\n",
    "        optimizer.zero_grad()\n",
    "        pred = model(inputs.to(device))\n",
    "        loss = criterion(pred,  targets.to(torch.device(\"cuda\")), torch.Tensor(max_val).to(torch.device(\"cuda\")))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        results['loss'] += loss.item() * len(inputs)\n",
    "        results['counter'] += len(inputs)\n",
    "        results['loss_arr'].append(loss.item())\n",
    "        if i % log_every == 0:\n",
    "           print(\"Train: Epoch: %d \\t Iteration: %d \\t loss: %.4f\" % (epoch, i, sum(results['loss_arr'][-10:])/len(results['loss_arr'][-10:])))\n",
    "        i += 1\n",
    "\n",
    "    scheduler.step()\n",
    "    return \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def val_loop(epoch, model, loader):\n",
    "   model.eval()\n",
    "   i = 0\n",
    "   results = {'loss': 0, 'counter': 0, 'loss_arr':[]}\n",
    "   with torch.no_grad():\n",
    "      for inputs, targets, _, _, _, _, max_val in loader:\n",
    "\n",
    "         inputs = inputs.to(device)[:,None,:,:]\n",
    "         targets = targets.to(device)[:,None,:,:]\n",
    "         max_val = torch.Tensor(max_val).to(device)\n",
    "\n",
    "         pred = model(inputs)\n",
    "         #loss = criterion(pred, targets, max_val)\n",
    "         loss = l2(pred, targets)\n",
    "         results['loss'] += loss.item() * len(inputs)\n",
    "         results['counter'] += len(inputs)\n",
    "         results['loss_arr'].append(loss.item())\n",
    "\n",
    "         if i % log_every == 0:\n",
    "             print(\"Val: Epoch %d \\t Iteration %d \\t loss %.4f\" % (epoch, i, sum(results['loss_arr'][-10:])/len(results['loss_arr'][-10:])))\n",
    "         i += 1\n",
    "         \n",
    "   return results['loss']/results['counter']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    results = {'epochs': [], 'losess': [], 'best_val': 1e10, 'best_epoch': 0}\n",
    "\n",
    "    for epoch in range(0, epochs):\n",
    "        #train_loop(epoch, model, train_loader)\n",
    "\n",
    "        val_loss = val_loop(epoch, model1, val_loader)\n",
    "\n",
    "        results['epochs'].append(epoch)\n",
    "        results['losess'].append(val_loss)\n",
    "\n",
    "        if val_loss < results['best_val']:\n",
    "            results['best_val'] = val_loss\n",
    "            results['best_epoch'] = epoch\n",
    "            \n",
    "            print(\"Val loss: %.4f  \\t epoch %d\" % (val_loss,epoch))\n",
    "            print(\"Best: val loss: %.4f \\t epoch %d\" % (results['best_val'], results['best_epoch']))\n",
    "\n",
    "\n",
    "        json_object = json.dumps(results, indent=4)\n",
    "        #with open( + \"/\" +  + \"/losess.json\", \"w\") as outfile:\n",
    "            #outfile.write(json_object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for FastMRICVT:\n\tMissing key(s) in state_dict: \"head.1.weight\", \"head.1.bias\", \"head.3.weight\", \"head.3.bias\". \n\tUnexpected key(s) in state_dict: \"stage0.blocks.1.norm1.weight\", \"stage0.blocks.1.norm1.bias\", \"stage0.blocks.1.attn.conv_proj_q.conv.weight\", \"stage0.blocks.1.attn.conv_proj_q.bn.weight\", \"stage0.blocks.1.attn.conv_proj_q.bn.bias\", \"stage0.blocks.1.attn.conv_proj_q.bn.running_mean\", \"stage0.blocks.1.attn.conv_proj_q.bn.running_var\", \"stage0.blocks.1.attn.conv_proj_q.bn.num_batches_tracked\", \"stage0.blocks.1.attn.conv_proj_k.conv.weight\", \"stage0.blocks.1.attn.conv_proj_k.bn.weight\", \"stage0.blocks.1.attn.conv_proj_k.bn.bias\", \"stage0.blocks.1.attn.conv_proj_k.bn.running_mean\", \"stage0.blocks.1.attn.conv_proj_k.bn.running_var\", \"stage0.blocks.1.attn.conv_proj_k.bn.num_batches_tracked\", \"stage0.blocks.1.attn.conv_proj_v.conv.weight\", \"stage0.blocks.1.attn.conv_proj_v.bn.weight\", \"stage0.blocks.1.attn.conv_proj_v.bn.bias\", \"stage0.blocks.1.attn.conv_proj_v.bn.running_mean\", \"stage0.blocks.1.attn.conv_proj_v.bn.running_var\", \"stage0.blocks.1.attn.conv_proj_v.bn.num_batches_tracked\", \"stage0.blocks.1.attn.proj_q.weight\", \"stage0.blocks.1.attn.proj_q.bias\", \"stage0.blocks.1.attn.proj_k.weight\", \"stage0.blocks.1.attn.proj_k.bias\", \"stage0.blocks.1.attn.proj_v.weight\", \"stage0.blocks.1.attn.proj_v.bias\", \"stage0.blocks.1.attn.proj.weight\", \"stage0.blocks.1.attn.proj.bias\", \"stage0.blocks.1.norm2.weight\", \"stage0.blocks.1.norm2.bias\", \"stage0.blocks.1.mlp.fc1.weight\", \"stage0.blocks.1.mlp.fc1.bias\", \"stage0.blocks.1.mlp.fc2.weight\", \"stage0.blocks.1.mlp.fc2.bias\", \"stage1.blocks.2.norm1.weight\", \"stage1.blocks.2.norm1.bias\", \"stage1.blocks.2.attn.conv_proj_q.conv.weight\", \"stage1.blocks.2.attn.conv_proj_q.bn.weight\", \"stage1.blocks.2.attn.conv_proj_q.bn.bias\", \"stage1.blocks.2.attn.conv_proj_q.bn.running_mean\", \"stage1.blocks.2.attn.conv_proj_q.bn.running_var\", \"stage1.blocks.2.attn.conv_proj_q.bn.num_batches_tracked\", \"stage1.blocks.2.attn.conv_proj_k.conv.weight\", \"stage1.blocks.2.attn.conv_proj_k.bn.weight\", \"stage1.blocks.2.attn.conv_proj_k.bn.bias\", \"stage1.blocks.2.attn.conv_proj_k.bn.running_mean\", \"stage1.blocks.2.attn.conv_proj_k.bn.running_var\", \"stage1.blocks.2.attn.conv_proj_k.bn.num_batches_tracked\", \"stage1.blocks.2.attn.conv_proj_v.conv.weight\", \"stage1.blocks.2.attn.conv_proj_v.bn.weight\", \"stage1.blocks.2.attn.conv_proj_v.bn.bias\", \"stage1.blocks.2.attn.conv_proj_v.bn.running_mean\", \"stage1.blocks.2.attn.conv_proj_v.bn.running_var\", \"stage1.blocks.2.attn.conv_proj_v.bn.num_batches_tracked\", \"stage1.blocks.2.attn.proj_q.weight\", \"stage1.blocks.2.attn.proj_q.bias\", \"stage1.blocks.2.attn.proj_k.weight\", \"stage1.blocks.2.attn.proj_k.bias\", \"stage1.blocks.2.attn.proj_v.weight\", \"stage1.blocks.2.attn.proj_v.bias\", \"stage1.blocks.2.attn.proj.weight\", \"stage1.blocks.2.attn.proj.bias\", \"stage1.blocks.2.norm2.weight\", \"stage1.blocks.2.norm2.bias\", \"stage1.blocks.2.mlp.fc1.weight\", \"stage1.blocks.2.mlp.fc1.bias\", \"stage1.blocks.2.mlp.fc2.weight\", \"stage1.blocks.2.mlp.fc2.bias\", \"stage1.blocks.3.norm1.weight\", \"stage1.blocks.3.norm1.bias\", \"stage1.blocks.3.attn.conv_proj_q.conv.weight\", \"stage1.blocks.3.attn.conv_proj_q.bn.weight\", \"stage1.blocks.3.attn.conv_proj_q.bn.bias\", \"stage1.blocks.3.attn.conv_proj_q.bn.running_mean\", \"stage1.blocks.3.attn.conv_proj_q.bn.running_var\", \"stage1.blocks.3.attn.conv_proj_q.bn.num_batches_tracked\", \"stage1.blocks.3.attn.conv_proj_k.conv.weight\", \"stage1.blocks.3.attn.conv_proj_k.bn.weight\", \"stage1.blocks.3.attn.conv_proj_k.bn.bias\", \"stage1.blocks.3.attn.conv_proj_k.bn.running_mean\", \"stage1.blocks.3.attn.conv_proj_k.bn.running_var\", \"stage1.blocks.3.attn.conv_proj_k.bn.num_batches_tracked\", \"stage1.blocks.3.attn.conv_proj_v.conv.weight\", \"stage1.blocks.3.attn.conv_proj_v.bn.weight\", \"stage1.blocks.3.attn.conv_proj_v.bn.bias\", \"stage1.blocks.3.attn.conv_proj_v.bn.running_mean\", \"stage1.blocks.3.attn.conv_proj_v.bn.running_var\", \"stage1.blocks.3.attn.conv_proj_v.bn.num_batches_tracked\", \"stage1.blocks.3.attn.proj_q.weight\", \"stage1.blocks.3.attn.proj_q.bias\", \"stage1.blocks.3.attn.proj_k.weight\", \"stage1.blocks.3.attn.proj_k.bias\", \"stage1.blocks.3.attn.proj_v.weight\", \"stage1.blocks.3.attn.proj_v.bias\", \"stage1.blocks.3.attn.proj.weight\", \"stage1.blocks.3.attn.proj.bias\", \"stage1.blocks.3.norm2.weight\", \"stage1.blocks.3.norm2.bias\", \"stage1.blocks.3.mlp.fc1.weight\", \"stage1.blocks.3.mlp.fc1.bias\", \"stage1.blocks.3.mlp.fc2.weight\", \"stage1.blocks.3.mlp.fc2.bias\", \"stage1.blocks.4.norm1.weight\", \"stage1.blocks.4.norm1.bias\", \"stage1.blocks.4.attn.conv_proj_q.conv.weight\", \"stage1.blocks.4.attn.conv_proj_q.bn.weight\", \"stage1.blocks.4.attn.conv_proj_q.bn.bias\", \"stage1.blocks.4.attn.conv_proj_q.bn.running_mean\", \"stage1.blocks.4.attn.conv_proj_q.bn.running_var\", \"stage1.blocks.4.attn.conv_proj_q.bn.num_batches_tracked\", \"stage1.blocks.4.attn.conv_proj_k.conv.weight\", \"stage1.blocks.4.attn.conv_proj_k.bn.weight\", \"stage1.blocks.4.attn.conv_proj_k.bn.bias\", \"stage1.blocks.4.attn.conv_proj_k.bn.running_mean\", \"stage1.blocks.4.attn.conv_proj_k.bn.running_var\", \"stage1.blocks.4.attn.conv_proj_k.bn.num_batches_tracked\", \"stage1.blocks.4.attn.conv_proj_v.conv.weight\", \"stage1.blocks.4.attn.conv_proj_v.bn.weight\", \"stage1.blocks.4.attn.conv_proj_v.bn.bias\", \"stage1.blocks.4.attn.conv_proj_v.bn.running_mean\", \"stage1.blocks.4.attn.conv_proj_v.bn.running_var\", \"stage1.blocks.4.attn.conv_proj_v.bn.num_batches_tracked\", \"stage1.blocks.4.attn.proj_q.weight\", \"stage1.blocks.4.attn.proj_q.bias\", \"stage1.blocks.4.attn.proj_k.weight\", \"stage1.blocks.4.attn.proj_k.bias\", \"stage1.blocks.4.attn.proj_v.weight\", \"stage1.blocks.4.attn.proj_v.bias\", \"stage1.blocks.4.attn.proj.weight\", \"stage1.blocks.4.attn.proj.bias\", \"stage1.blocks.4.norm2.weight\", \"stage1.blocks.4.norm2.bias\", \"stage1.blocks.4.mlp.fc1.weight\", \"stage1.blocks.4.mlp.fc1.bias\", \"stage1.blocks.4.mlp.fc2.weight\", \"stage1.blocks.4.mlp.fc2.bias\", \"stage1.blocks.5.norm1.weight\", \"stage1.blocks.5.norm1.bias\", \"stage1.blocks.5.attn.conv_proj_q.conv.weight\", \"stage1.blocks.5.attn.conv_proj_q.bn.weight\", \"stage1.blocks.5.attn.conv_proj_q.bn.bias\", \"stage1.blocks.5.attn.conv_proj_q.bn.running_mean\", \"stage1.blocks.5.attn.conv_proj_q.bn.running_var\", \"stage1.blocks.5.attn.conv_proj_q.bn.num_batches_tracked\", \"stage1.blocks.5.attn.conv_proj_k.conv.weight\", \"stage1.blocks.5.attn.conv_proj_k.bn.weight\", \"stage1.blocks.5.attn.conv_proj_k.bn.bias\", \"stage1.blocks.5.attn.conv_proj_k.bn.running_mean\", \"stage1.blocks.5.attn.conv_proj_k.bn.running_var\", \"stage1.blocks.5.attn.conv_proj_k.bn.num_batches_tracked\", \"stage1.blocks.5.attn.conv_proj_v.conv.weight\", \"stage1.blocks.5.attn.conv_proj_v.bn.weight\", \"stage1.blocks.5.attn.conv_proj_v.bn.bias\", \"stage1.blocks.5.attn.conv_proj_v.bn.running_mean\", \"stage1.blocks.5.attn.conv_proj_v.bn.running_var\", \"stage1.blocks.5.attn.conv_proj_v.bn.num_batches_tracked\", \"stage1.blocks.5.attn.proj_q.weight\", \"stage1.blocks.5.attn.proj_q.bias\", \"stage1.blocks.5.attn.proj_k.weight\", \"stage1.blocks.5.attn.proj_k.bias\", \"stage1.blocks.5.attn.proj_v.weight\", \"stage1.blocks.5.attn.proj_v.bias\", \"stage1.blocks.5.attn.proj.weight\", \"stage1.blocks.5.attn.proj.bias\", \"stage1.blocks.5.norm2.weight\", \"stage1.blocks.5.norm2.bias\", \"stage1.blocks.5.mlp.fc1.weight\", \"stage1.blocks.5.mlp.fc1.bias\", \"stage1.blocks.5.mlp.fc2.weight\", \"stage1.blocks.5.mlp.fc2.bias\", \"head.4.weight\", \"head.4.bias\". \n\tsize mismatch for head.0.weight: copying a param with shape torch.Size([192, 48, 3, 3]) from checkpoint, the shape in current model is torch.Size([192, 48, 2, 2]).",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[1;32mIn [7]\u001b[0m, in \u001b[0;36m<cell line: 36>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     28\u001b[0m encoder \u001b[38;5;241m=\u001b[39m CMTEncoder(\n\u001b[0;32m     29\u001b[0m     img_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m320\u001b[39m, in_chans\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, num_classes\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, patch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m, embed_dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m64\u001b[39m,\n\u001b[0;32m     30\u001b[0m     depths\u001b[38;5;241m=\u001b[39m[\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m3\u001b[39m], kv_scale\u001b[38;5;241m=\u001b[39m[\u001b[38;5;241m8\u001b[39m, \u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m2\u001b[39m], num_heads\u001b[38;5;241m=\u001b[39m[\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m8\u001b[39m], mlp_ratio\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4.\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     33\u001b[0m     use_ghost_ffn\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, use_multi_merge\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, norm_layer\u001b[38;5;241m=\u001b[39mnn\u001b[38;5;241m.\u001b[39mLayerNorm\n\u001b[0;32m     34\u001b[0m )\n\u001b[0;32m     35\u001b[0m model2 \u001b[38;5;241m=\u001b[39m FastMRIEncoderDecoder(encoder)\n\u001b[1;32m---> 36\u001b[0m \u001b[43mmodel1\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_state_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtrained_models/best_modelmk1.pt\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcpu\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     37\u001b[0m \u001b[38;5;66;03m#model2.load_state_dict(torch.load('trained_models/best_modelCMT.pt', map_location=torch.device('cpu')))\u001b[39;00m\n\u001b[0;32m     38\u001b[0m val_loader \u001b[38;5;241m=\u001b[39m DataLoader(train, batch_size\u001b[38;5;241m=\u001b[39mbatch_size, shuffle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\pinkp\\Anaconda3\\envs\\AdvML\\lib\\site-packages\\torch\\nn\\modules\\module.py:1604\u001b[0m, in \u001b[0;36mModule.load_state_dict\u001b[1;34m(self, state_dict, strict)\u001b[0m\n\u001b[0;32m   1599\u001b[0m         error_msgs\u001b[38;5;241m.\u001b[39minsert(\n\u001b[0;32m   1600\u001b[0m             \u001b[38;5;241m0\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMissing key(s) in state_dict: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m   1601\u001b[0m                 \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(k) \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m missing_keys)))\n\u001b[0;32m   1603\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(error_msgs) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m-> 1604\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mError(s) in loading state_dict for \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m   1605\u001b[0m                        \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(error_msgs)))\n\u001b[0;32m   1606\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _IncompatibleKeys(missing_keys, unexpected_keys)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for FastMRICVT:\n\tMissing key(s) in state_dict: \"head.1.weight\", \"head.1.bias\", \"head.3.weight\", \"head.3.bias\". \n\tUnexpected key(s) in state_dict: \"stage0.blocks.1.norm1.weight\", \"stage0.blocks.1.norm1.bias\", \"stage0.blocks.1.attn.conv_proj_q.conv.weight\", \"stage0.blocks.1.attn.conv_proj_q.bn.weight\", \"stage0.blocks.1.attn.conv_proj_q.bn.bias\", \"stage0.blocks.1.attn.conv_proj_q.bn.running_mean\", \"stage0.blocks.1.attn.conv_proj_q.bn.running_var\", \"stage0.blocks.1.attn.conv_proj_q.bn.num_batches_tracked\", \"stage0.blocks.1.attn.conv_proj_k.conv.weight\", \"stage0.blocks.1.attn.conv_proj_k.bn.weight\", \"stage0.blocks.1.attn.conv_proj_k.bn.bias\", \"stage0.blocks.1.attn.conv_proj_k.bn.running_mean\", \"stage0.blocks.1.attn.conv_proj_k.bn.running_var\", \"stage0.blocks.1.attn.conv_proj_k.bn.num_batches_tracked\", \"stage0.blocks.1.attn.conv_proj_v.conv.weight\", \"stage0.blocks.1.attn.conv_proj_v.bn.weight\", \"stage0.blocks.1.attn.conv_proj_v.bn.bias\", \"stage0.blocks.1.attn.conv_proj_v.bn.running_mean\", \"stage0.blocks.1.attn.conv_proj_v.bn.running_var\", \"stage0.blocks.1.attn.conv_proj_v.bn.num_batches_tracked\", \"stage0.blocks.1.attn.proj_q.weight\", \"stage0.blocks.1.attn.proj_q.bias\", \"stage0.blocks.1.attn.proj_k.weight\", \"stage0.blocks.1.attn.proj_k.bias\", \"stage0.blocks.1.attn.proj_v.weight\", \"stage0.blocks.1.attn.proj_v.bias\", \"stage0.blocks.1.attn.proj.weight\", \"stage0.blocks.1.attn.proj.bias\", \"stage0.blocks.1.norm2.weight\", \"stage0.blocks.1.norm2.bias\", \"stage0.blocks.1.mlp.fc1.weight\", \"stage0.blocks.1.mlp.fc1.bias\", \"stage0.blocks.1.mlp.fc2.weight\", \"stage0.blocks.1.mlp.fc2.bias\", \"stage1.blocks.2.norm1.weight\", \"stage1.blocks.2.norm1.bias\", \"stage1.blocks.2.attn.conv_proj_q.conv.weight\", \"stage1.blocks.2.attn.conv_proj_q.bn.weight\", \"stage1.blocks.2.attn.conv_proj_q.bn.bias\", \"stage1.blocks.2.attn.conv_proj_q.bn.running_mean\", \"stage1.blocks.2.attn.conv_proj_q.bn.running_var\", \"stage1.blocks.2.attn.conv_proj_q.bn.num_batches_tracked\", \"stage1.blocks.2.attn.conv_proj_k.conv.weight\", \"stage1.blocks.2.attn.conv_proj_k.bn.weight\", \"stage1.blocks.2.attn.conv_proj_k.bn.bias\", \"stage1.blocks.2.attn.conv_proj_k.bn.running_mean\", \"stage1.blocks.2.attn.conv_proj_k.bn.running_var\", \"stage1.blocks.2.attn.conv_proj_k.bn.num_batches_tracked\", \"stage1.blocks.2.attn.conv_proj_v.conv.weight\", \"stage1.blocks.2.attn.conv_proj_v.bn.weight\", \"stage1.blocks.2.attn.conv_proj_v.bn.bias\", \"stage1.blocks.2.attn.conv_proj_v.bn.running_mean\", \"stage1.blocks.2.attn.conv_proj_v.bn.running_var\", \"stage1.blocks.2.attn.conv_proj_v.bn.num_batches_tracked\", \"stage1.blocks.2.attn.proj_q.weight\", \"stage1.blocks.2.attn.proj_q.bias\", \"stage1.blocks.2.attn.proj_k.weight\", \"stage1.blocks.2.attn.proj_k.bias\", \"stage1.blocks.2.attn.proj_v.weight\", \"stage1.blocks.2.attn.proj_v.bias\", \"stage1.blocks.2.attn.proj.weight\", \"stage1.blocks.2.attn.proj.bias\", \"stage1.blocks.2.norm2.weight\", \"stage1.blocks.2.norm2.bias\", \"stage1.blocks.2.mlp.fc1.weight\", \"stage1.blocks.2.mlp.fc1.bias\", \"stage1.blocks.2.mlp.fc2.weight\", \"stage1.blocks.2.mlp.fc2.bias\", \"stage1.blocks.3.norm1.weight\", \"stage1.blocks.3.norm1.bias\", \"stage1.blocks.3.attn.conv_proj_q.conv.weight\", \"stage1.blocks.3.attn.conv_proj_q.bn.weight\", \"stage1.blocks.3.attn.conv_proj_q.bn.bias\", \"stage1.blocks.3.attn.conv_proj_q.bn.running_mean\", \"stage1.blocks.3.attn.conv_proj_q.bn.running_var\", \"stage1.blocks.3.attn.conv_proj_q.bn.num_batches_tracked\", \"stage1.blocks.3.attn.conv_proj_k.conv.weight\", \"stage1.blocks.3.attn.conv_proj_k.bn.weight\", \"stage1.blocks.3.attn.conv_proj_k.bn.bias\", \"stage1.blocks.3.attn.conv_proj_k.bn.running_mean\", \"stage1.blocks.3.attn.conv_proj_k.bn.running_var\", \"stage1.blocks.3.attn.conv_proj_k.bn.num_batches_tracked\", \"stage1.blocks.3.attn.conv_proj_v.conv.weight\", \"stage1.blocks.3.attn.conv_proj_v.bn.weight\", \"stage1.blocks.3.attn.conv_proj_v.bn.bias\", \"stage1.blocks.3.attn.conv_proj_v.bn.running_mean\", \"stage1.blocks.3.attn.conv_proj_v.bn.running_var\", \"stage1.blocks.3.attn.conv_proj_v.bn.num_batches_tracked\", \"stage1.blocks.3.attn.proj_q.weight\", \"stage1.blocks.3.attn.proj_q.bias\", \"stage1.blocks.3.attn.proj_k.weight\", \"stage1.blocks.3.attn.proj_k.bias\", \"stage1.blocks.3.attn.proj_v.weight\", \"stage1.blocks.3.attn.proj_v.bias\", \"stage1.blocks.3.attn.proj.weight\", \"stage1.blocks.3.attn.proj.bias\", \"stage1.blocks.3.norm2.weight\", \"stage1.blocks.3.norm2.bias\", \"stage1.blocks.3.mlp.fc1.weight\", \"stage1.blocks.3.mlp.fc1.bias\", \"stage1.blocks.3.mlp.fc2.weight\", \"stage1.blocks.3.mlp.fc2.bias\", \"stage1.blocks.4.norm1.weight\", \"stage1.blocks.4.norm1.bias\", \"stage1.blocks.4.attn.conv_proj_q.conv.weight\", \"stage1.blocks.4.attn.conv_proj_q.bn.weight\", \"stage1.blocks.4.attn.conv_proj_q.bn.bias\", \"stage1.blocks.4.attn.conv_proj_q.bn.running_mean\", \"stage1.blocks.4.attn.conv_proj_q.bn.running_var\", \"stage1.blocks.4.attn.conv_proj_q.bn.num_batches_tracked\", \"stage1.blocks.4.attn.conv_proj_k.conv.weight\", \"stage1.blocks.4.attn.conv_proj_k.bn.weight\", \"stage1.blocks.4.attn.conv_proj_k.bn.bias\", \"stage1.blocks.4.attn.conv_proj_k.bn.running_mean\", \"stage1.blocks.4.attn.conv_proj_k.bn.running_var\", \"stage1.blocks.4.attn.conv_proj_k.bn.num_batches_tracked\", \"stage1.blocks.4.attn.conv_proj_v.conv.weight\", \"stage1.blocks.4.attn.conv_proj_v.bn.weight\", \"stage1.blocks.4.attn.conv_proj_v.bn.bias\", \"stage1.blocks.4.attn.conv_proj_v.bn.running_mean\", \"stage1.blocks.4.attn.conv_proj_v.bn.running_var\", \"stage1.blocks.4.attn.conv_proj_v.bn.num_batches_tracked\", \"stage1.blocks.4.attn.proj_q.weight\", \"stage1.blocks.4.attn.proj_q.bias\", \"stage1.blocks.4.attn.proj_k.weight\", \"stage1.blocks.4.attn.proj_k.bias\", \"stage1.blocks.4.attn.proj_v.weight\", \"stage1.blocks.4.attn.proj_v.bias\", \"stage1.blocks.4.attn.proj.weight\", \"stage1.blocks.4.attn.proj.bias\", \"stage1.blocks.4.norm2.weight\", \"stage1.blocks.4.norm2.bias\", \"stage1.blocks.4.mlp.fc1.weight\", \"stage1.blocks.4.mlp.fc1.bias\", \"stage1.blocks.4.mlp.fc2.weight\", \"stage1.blocks.4.mlp.fc2.bias\", \"stage1.blocks.5.norm1.weight\", \"stage1.blocks.5.norm1.bias\", \"stage1.blocks.5.attn.conv_proj_q.conv.weight\", \"stage1.blocks.5.attn.conv_proj_q.bn.weight\", \"stage1.blocks.5.attn.conv_proj_q.bn.bias\", \"stage1.blocks.5.attn.conv_proj_q.bn.running_mean\", \"stage1.blocks.5.attn.conv_proj_q.bn.running_var\", \"stage1.blocks.5.attn.conv_proj_q.bn.num_batches_tracked\", \"stage1.blocks.5.attn.conv_proj_k.conv.weight\", \"stage1.blocks.5.attn.conv_proj_k.bn.weight\", \"stage1.blocks.5.attn.conv_proj_k.bn.bias\", \"stage1.blocks.5.attn.conv_proj_k.bn.running_mean\", \"stage1.blocks.5.attn.conv_proj_k.bn.running_var\", \"stage1.blocks.5.attn.conv_proj_k.bn.num_batches_tracked\", \"stage1.blocks.5.attn.conv_proj_v.conv.weight\", \"stage1.blocks.5.attn.conv_proj_v.bn.weight\", \"stage1.blocks.5.attn.conv_proj_v.bn.bias\", \"stage1.blocks.5.attn.conv_proj_v.bn.running_mean\", \"stage1.blocks.5.attn.conv_proj_v.bn.running_var\", \"stage1.blocks.5.attn.conv_proj_v.bn.num_batches_tracked\", \"stage1.blocks.5.attn.proj_q.weight\", \"stage1.blocks.5.attn.proj_q.bias\", \"stage1.blocks.5.attn.proj_k.weight\", \"stage1.blocks.5.attn.proj_k.bias\", \"stage1.blocks.5.attn.proj_v.weight\", \"stage1.blocks.5.attn.proj_v.bias\", \"stage1.blocks.5.attn.proj.weight\", \"stage1.blocks.5.attn.proj.bias\", \"stage1.blocks.5.norm2.weight\", \"stage1.blocks.5.norm2.bias\", \"stage1.blocks.5.mlp.fc1.weight\", \"stage1.blocks.5.mlp.fc1.bias\", \"stage1.blocks.5.mlp.fc2.weight\", \"stage1.blocks.5.mlp.fc2.bias\", \"head.4.weight\", \"head.4.bias\". \n\tsize mismatch for head.0.weight: copying a param with shape torch.Size([192, 48, 3, 3]) from checkpoint, the shape in current model is torch.Size([192, 48, 2, 2])."
     ]
    }
   ],
   "source": [
    "train_loader = DataLoader(train, batch_size=batch_size, shuffle = True)\n",
    "val_loader = DataLoader(val, batch_size=batch_size, shuffle = True)\n",
    "\n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 170498071/170498071 [00:01<00:00, 109461919.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
